---
title : 'R-32일차(2018.2.8)'
---

    32-1. Naive Bayes
          : 베이지 확률이론
    32-2. 라플라스 추정기
    32-3. naiveBayes()   
    32-4. predict()


# 32-1. 나이브 베이즈(Naive Bayes)

    - 확률 : 어떤 현상이 일어날 가능성을 측정하는 척도 (0 ~ 1)
    
      기상학자가 날씨예보를 할 때 일반적으로 "비 올 확률 70%" 라는 용어를 사용해 예측함.
      어떻게 예측을 할 수 있을까요?
      
      : 과거의 이 시점에 비가 왔던 때와 유사하게 측정된 대기조건으로 비가 올 확률을
        구하지 않을까요? 
        
      70% 의미?
      
      : 과거의 이런 경우가 10번 중 7번은 비가 왔음을 의미함.
      
      
    - 시행 : 동일한 조건, 여러번 반복, 그 결과가 우연에 의해서 지배되는 실험이나 관찰
        ex) 그날의 날씨, 동전 던지기, 스펨메일, 매일 같은 사건이 일어날 한번의 기회

    - 표본공간 : 시행의 결과 집합
      
    - 사건 : 표본공간의 부분집합 
        ex) 화창하거나 비가 올 날씨, 동전 던지기에서 앞면, 뒷면, 스팸메일, 햄메일, 
            주사위 던지기에서 짝수눈이 나올 사건
            
    
    확률 = (사건이 일어난 시도의 수) / (총사건의 수)
    
      
    - 근원사건 : 원소의 갯수가 1개인 사건(표본공간의 부분집합)  
          ex) 주사위 던지기를 통해 1의 눈이 나올 사건 
          
    - 합사건 : A ∪ B

    - 곱사건 : A ∩ B

    - 여사건 : A^c
    
    - 배반사건 : A ∩ B = 0
    
    - 수학적 확률 : 근원사건이 일어날 가능성이 모두 같을때 
       ex) 주사위 1,2 나오는 사건 둘다 확률이 1/6으로 같다
       
       A라는 사건이 일어날 확률, 
                          P(A) = n(A)/n(S) 
                               = 사건의 원소의 갯수 / 표본공간의 원소의 갯수
                               = 특정사건이 일어나는 수 / 전체 경우의 수
                           
       단, S = 표본공간, 공집합, S 자신도 S의 부분집합
                          P(A) = 0, 공사건(일어나지 않을 사건)
                          P(S) = 1, 전사건(항상 일어나는 사건)
                          
       그래서 확률의 성질
                         0 ≤ P(A) ≤ 1
        
                          
    - 기하학적 확률 : 경우의 수나 원소의 갯수를 셀 수 없는 경우
          
    
    - 통계학적(경험적) 확률 : 근원사건이 일어날 가능성이 서로 다를때
        ex) 윳놀이
        
                  lim   경우의 수(r) / 던진 총 횟수(n) 
                  n → ∞


[문제219] 주사위 1개를 던졌울때 A를 4이하의 눈이 나오는 사건, B를 짝수의 눈이 나오는 사건
          사건 A, 사건 B가 일어날 확률은? 
     
     S = {1,2,3,4,5,6}
     A = {1,2,3,4}
     B = {2,4,6}


P(A) = 4/6 = 2/3
P(B) = 3/6 = 1/2 
```{r}
S <- c(1:6)
A <- c(1:4)
B <- seq(2,6,2)
S;A;B
```

```{r}
# P(A)
NROW(A)/NROW(S)

# P(B)
NROW(B)/NROW(S)
```

     - 결합확률, 동시확률, 곱확률
       : 둘 이상의 사건이 모두 일어날 확률(즉, 동시에 일어날 확률)

       ex) A와 B가 동시에 일어날 확률
           P(A,B) = n(A ∩ B)/n(S) = P(A ∩ B)
           
           * A ∩ B = 0, P(A,B) = P(A) × P(B)
           * A ∩ B ≠ 0, P(A,B) = P(A|B) × P(B) = P(B|A) × P(A)

[문제220] 주사위 1개를 던졌울때 A를 4이하의 눈이 나오는 사건, B를 짝수의 눈이 나오는 사건
          사건 A, 사건 B이 동시에 일어날 확률은? 
     
     S = {1,2,3,4,5,6}
     A = {1,2,3,4}
     B = {2,4,6}
     
     A ∩ B = {2,4}     
     
     P(A ∩ B) = 1/3



     - 조건부확률 : A라는 사건이 일어났을 때, B라는 사건이 일어날 확률
        
       P(B|A) = P(A,B) / P(A) = P(A ∩ B) / P(A) (단, P(A) ≠ 0)
       
       P(눈) = 눈이 많이 올 확률
       P(교통사고) = 교통사고가 발생할 확률
       
       P(교통사고|눈) = 눈이 많이 오는 날에 교통사고가 발생할 확률


[문제221] 주사위 1개를 던졌을때 A 사건(4개 이하의 눈이 나오는 사건)이
          일어났을때 B 사건(짝수의 눈이 나오는 사건)이 일어날 확률은?
     
     S = {1,2,3,4,5,6}
     A = {1,2,3,4}
     B = {2,4,6}
     
     A ∩ B = {2,4}
     P(A) = 2/3, P(B) = 1/2, P(A ∩ B) = 1/3     

     P(B|A) = 2/4 = 1/2 = P(B)
     P(A|B) = 2/3 = P(A)


조건부확률은 표본공간이 주어진 사건으로 바뀐확률 


[문제222] 
    안경(O) 안경(X)
-------------------
남    5        7
여    6        4

A : 남학생일 사건
B : 안경은 끼고 있는 사건

P(B|A) = 5/12

--------------------------------------------------------------------------------

    - 곱셈정리(승법정리)

            P(A ∩ B) = P(A|B) × P(B) = P(B|A) × P(A) 

    - 독립사건 : 두 사건이 동시에 일어났는데 두 사건이 서로 전혀 연관되지 않음.
        ex) 동전던지기의 결과와 화창한 날씨하고는 서로 독립적 

            P(A,B) = P(A) × P(B)
            
    - 종속사건 : 사건 A가 일어났을 경우와 일어나지 않았을 경우에 따라서
                 사건 B가 일어날 확률이 다를때이다.(즉, A가 B에 영향을 준다) 
                 
            P(A ∩ B) = P(A|B) × P(B) = P(B|A) × P(A) 
            P(B|A) = P(A,B) / P(A) = P(A ∩ B) / P(A) (단, P(A) ≠ 0)
            P(A|B) = P(A,B) / P(B) = P(A ∩ B) / P(B) (단, P(B) ≠ 0)



[문제223] 모든 메시지의 20%는 스팸이고 모든 메시지의 5%는 '비아그라'라는 단어가
          들어 있다면 스팸과 비아그라가 함께 일어날 확률은? 
          (단, 독립이라고 하자)
          
A : 스팸, B : 비아그라
P(A) = 0.2
P(B) = 0.05

P(A ∩ B) = 0.2 × 0.05 = 0.01


# 베이지 확률이론

    - 유사한 증거를 기반으로 한 사건의 유사성을 추정하는 개념
    
    P(A|B) = P(A ∩ B) / P(B) 
           = P(B|A) × P(A) / P(B) 
           = P(B|A) × P(A) / [P(B|A) × P(A) + P(B|A^c) × P(A^c)]

    P(A|B) : 사후확률
    P(B|A) : 우도(likelihood), 가능성
    P(A) : 사전확률
    P(B) : 주변우도 


P(스팸|비아그라) = P(비아그라|스팸) × P(스팸) / P(비아그라)

우도 : P(비아그라|스팸) 비아그라 단어가 이전 스팸메시지에 사용됬을 확률
주변우도 : P(비아그라) 모든 메시지에 비아그라가 나타날 확률

                비아그라
             Y     N    총합
     스팸    4     16    20
     햄      1     79    80
     총합    5     95    100

P(비아그라|스팸) = 4/20 = 1/5 = 0.2
P(스팸) = 20/100 = 1/5 = 0.2
P(비아그라) = 5/100 = 0.05 = 1/200


P(스팸|비아그라) = 0.8 = 4/5 (80%)
```{r}
0.2*0.2 / 0.05
```

∴ 비아그라라는 단어가 포함되어 있으면 스팸일 확률이 80% 이다.


문제점은 비아그라 단어 하나만 가지고 분류를 하면 처방전도 스팸처리 될
확률이 높으니 다른 단어들도 같이 포함시켜서 확률을 구해야 한다.

         비아그라       돈         식료품        주소삭제
          Y   N        Y   N       Y    N         Y    N
    스팸  4   16       10  10      0   20         12   8     20
    햄    1   79       14  66      8   72         23   57    80
          5   95       24  76      8   92         35   65   100
          
          
 비아그라와 주소삭제는 포함하고 돈과 식료품은 포함하지 않은
 메세지가 스팸일 확률은 어떻게 되는가?
 
 비아그라 = yes, 돈 = no, 식료품 = no, 주소삭제 = yes
          
  ㄱ : 존재하지 않는다(부정)
  ㅋ : 존재한다(긍정)
  
     P(스팸|비아그라 ∩ ㄱ돈 ∩ ㄱ식료품 ∩ 주소삭제)
  
         P(비아그라 ∩ ㄱ돈 ∩ ㄱ식료품 ∩ 주소삭제|스팸) × P(스팸)
     =  ------------------------------------------------------
            P(비아그라 ∩ ㄱ돈 ∩ ㄱ식료품 ∩ 주소삭제)
            
            
P(비아그라 ∩ ㄱ돈 ∩ ㄱ식료품 ∩ 주소삭제|스팸) 
= P(비아그라|스팸) P(ㄱ돈|스팸) P(ㄱ식료품|스팸) P(주소삭제|스팸)             
= 4/20 × 10/20 × 20/20 × 12/20            
= 1/5 × 1/2 × 3/5
= 3/50 = 0.06
            
P(스팸) = 20/100 = 0.2            
```{r}
.06*.2
```
            
            
P(비아그라 ∩ ㄱ돈 ∩ ㄱ식료품 ∩ 주소삭제) 
= P(비아그라 ∩ ㄱ돈 ∩ ㄱ식료품 ∩ 주소삭제|스팸) × P(스팸) 
  + P(비아그라 ∩ ㄱ돈 ∩ ㄱ식료품 ∩ 주소삭제|햄) × P(햄) 
  
```{r}
(1/80)*(66/80)*(72/80)*(23/80)*(80/100)
```

```{r}
0.012/(0.012+0.002)
```

            
∴ 비아그라와 주소삭제는 포함하고 돈과 식료품은 포함하지 않은 메세지가 스팸일 확률은 86% 이다.            
            


결론 : 
            
P(비아그라 ∩ 돈 ∩ 식료품 ∩ 주소삭제|스팸) × P(스팸) = 0

P(비아그라 ∩ 돈 ∩ 식료품 ∩ 주소삭제|햄) × P(햄)
```{r}
(1/80)*(14/80)*(8/80)*(23/80)*(80/100)
```
            

스팸 확률 : 0/(0+5.03125e-05) = 0
햄   확률 : 5.03125e-05/(0+5.03125e-05) = 1
          
            
# 32-3. 라플라스 추정기
: 확률이 0이 되지 않기 위해서 빈도표의 각 값에 작은수를 추가한다.
  각각의 값이 1을 더해서 수행
  
          https://en.wikipedia.org/wiki/Additive_smoothing
            
    
    P(비아그라 ∩ 돈 ∩ 식료품 ∩ 주소삭제|스팸) × P(스팸) 
    = (4+1/20+1*4) * (10+1/20+1*4) * (0+1/20+1*4) * (12+1/20+1*4) * (20/100)        
```{r}
A <- (5/24) * (11/24) * (1/24) * (13/24) * (20/100);A   
```
       
    P(비아그라 ∩ 돈 ∩ 식료품 ∩ 주소삭제|햄) × P(햄)
    = (1+1/80+1*4)*(14+1/80+1*4)*(8+1/80+1*4)*(23+1/80+1*4) * (80/100)
```{r}
B <- (2/84)*(15/84)*(9/84)*(24/84)*(80/100);B
```
            
            
```{r}
# 비아그라, 돈, 식료품, 주소삭제 메세지를 받았을 때 스팸일 확률
A/(A+B)

# 비아그라, 돈, 식료품, 주소삭제 메세지를 받았을 때 햄일 확률
B/(A+B)
```
            
            
---------------------------------------------         


# 32-4. naiveBayes()          
```{r}
install.packages("e1071") # 오스트리아 수도 빈 비엔나 기술통계학과 개발 
library(e1071)
```
          
          
```{r}
mail <- read.csv("c:/r/spam.csv", header = T)
mail[is.na(mail)] <- 0
mail
str(mail) # 메일종류 factor여야 된다 
```
          

 - 예측모델 학습           
```{r}
m <- naiveBayes(mail[2:13], mail$메일종류, laplace = 0)
m  # 훈련모델
```
          
     
# 32-5. predict()     
  
  - 훈련모델 m을 기준으로 예측값 m2를 생성(실제값과 비교)
```{r}
m2 <- predict(m, mail[2:13])
m2
m2 == mail[,14]
```
          
          
```{r}
sum(mail$메일종류 != m2)
```
        
          
 - 6번째 메일은 문제가 있다(잘못 분류된 것)    
```{r}
mail[mail$메일종류 != m2,]
```
    
  
  - cross-table   
```{r}
library(gmodels)
```
    
    
```{r}
CrossTable(m2, mail$메일종류,
           prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
           dnn = c("predicted","actual"))
```
    
    
```{r}
install.packages("coefplot")
library(coefplot)
```
    
    
```{r}
multiplot()
```

    
```{r}
ggplot(mail, aes(x = ))
```
    
    
  - test 데이터로 실습
  
```{r}
test <- mail[6,]
test <- test[-1]
test$메일종류 <- NA
test$대학교 <- 1
test
```
    
    
```{r}
predict(m, test[-13])
```
    
    
---------------------------------   
    
    
```{r}
movie <- read.csv("c:/r/movie.csv", header = T)
str(movie)
```
    
   
```{r}
movie
```
   
   
```{r}
train <- naiveBayes(movie[-6], movie$장르, laplace = 0)
train
```
    
          20,여성,it,미혼
```{r}
p <- predict(train, movie[-6])
p
```

```{r}
sum(p != movie$장르)
movie[p != movie$장르,]
```

          
```{r}
p <- predict(train, 
             data.frame(나이 = '20대', 성별 = '여', 직업 = 'IT', 
                          결혼여부 = 'NO', 이성친구 = 'NO'))
p
```
          
     ※  문자는 factor 가 되야지 결과나옴 그런데 왜 이모양이냐 ㅠㅠ    
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
